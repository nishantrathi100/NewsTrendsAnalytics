{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = pd.read_csv('News_Final.csv')\n",
    "dfFb_Ec = pd.read_csv('Facebook_Economy.csv')\n",
    "dfFb_Ms = pd.read_csv('Facebook_Microsoft.csv')\n",
    "dfFb_Ob = pd.read_csv('Facebook_Obama.csv')\n",
    "dfFb_Pa = pd.read_csv('Facebook_Palestine.csv')\n",
    "dfGo_Pa = pd.read_csv('GooglePlus_Palestine.csv')\n",
    "dfGo_Ob = pd.read_csv('GooglePlus_Obama.csv')\n",
    "dfGo_Ms = pd.read_csv('GooglePlus_Microsoft.csv')\n",
    "dfGo_Ec = pd.read_csv('GooglePlus_Economy.csv')\n",
    "dfLd_Pa = pd.read_csv('LinkedIn_Palestine.csv')\n",
    "dfLd_Ob = pd.read_csv('LinkedIn_Obama.csv')\n",
    "dfLd_Ms = pd.read_csv('LinkedIn_Microsoft.csv')\n",
    "dfLd_Ec = pd.read_csv('LinkedIn_Economy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the items which was never shared or with share counts = 0\n",
    "df = dfFinal[(dfFinal.Facebook != -1) & (dfFinal.GooglePlus != -1) & (dfFinal.LinkedIn != -1) & (dfFinal.Facebook != 0) & (dfFinal.GooglePlus != 0) & (dfFinal.LinkedIn != 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edit original Data frame to assign group rank\n",
    "def assignRank(row,rankDictionary):\n",
    "    if row.IDLink in rankDictionary:\n",
    "        return rankDictionary[row.IDLink]\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rank_model(df):\n",
    "    #removing time from publish date\n",
    "    df['PublishDate'] = df['PublishDate'].astype('datetime64[ns]')\n",
    "    df['DateOnly'] = df['PublishDate'].dt.date\n",
    "\n",
    "    #count number of days since Jan 1 1970. These columns would be used to form groups of 3 days\n",
    "    df['DaysSince1'] = (pd.to_datetime(df['DateOnly']) - pd.datetime(1970,1,1)).dt.days\n",
    "    df['DaysSince1'] = df['DaysSince1'].subtract(df['DaysSince1'].min()).add(1)\n",
    "    df['DaysSince2'] = df['DaysSince1'] + 1\n",
    "    df['DaysSince3'] = df['DaysSince1'] + 2\n",
    "\n",
    "    print \"Calculating rank...\"\n",
    "    # Calculate rank of the news item within the 3 day window group\n",
    "\n",
    "    loop_start = df['DaysSince1'].min()\n",
    "    loop_end = df['DaysSince1'].max()\n",
    "    print loop_start\n",
    "    print loop_end\n",
    "    rankDictionary = {}\n",
    "    for x in range(loop_start, loop_end):\n",
    "        df_temp = df[(df.DaysSince1 == x) | (df.DaysSince2 == x) | (df.DaysSince3 == x)]\n",
    "        df_temp.sort_values(by='Facebook')# Made it ascending so that we rank them in reverse order #, ascending=False)\n",
    "        df_temp['GroupRanking'] = df_temp['Facebook'].rank(ascending=False)\n",
    "        for index, row in df_temp.iterrows():\n",
    "            if row['DaysSince1'] == x:\n",
    "                rankDictionary[row['IDLink']] = row['GroupRanking']\n",
    "    df['groupRank'] = df.apply (lambda row: assignRank (row,rankDictionary),axis=1)\n",
    "    df['Facebook'] = df['Facebook'].apply(lambda x: np.log(x + 1))\n",
    "    #Split DataFrame into X and Y\n",
    "    #df_X_Without_Rank = pd.get_dummies(df[['Source', 'Topic', 'SentimentTitle', 'SentimentHeadline']])\n",
    "    df_X = pd.get_dummies(df[['Source', 'Topic', 'SentimentTitle', 'SentimentHeadline', 'groupRank']])\n",
    "    df_Y = df[['Facebook']]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_X, df_Y, test_size=0.25)\n",
    "    return df, xtrain, ytrain,xtest, ytest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model(df):\n",
    "    df['Facebook'] = df['Facebook'].apply(lambda x: np.log(x + 1))\n",
    "    #Split DataFrame into X and Y\n",
    "\n",
    "    #df_X_Without_Rank = pd.get_dummies(df[['Source', 'Topic', 'SentimentTitle', 'SentimentHeadline']])\n",
    "    df_X = pd.get_dummies(df[['Source', 'Topic', 'SentimentTitle', 'SentimentHeadline']])\n",
    "    df_Y = df[['Facebook']]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_X, df_Y, test_size=0.25)\n",
    "    return df, xtrain, ytrain,xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models= [basic_model(df),rank_model(df)]\n",
    "model_names = [\"Basic Model\",\"Model_With_Ranking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17496, 1738)\n",
      "(17496, 1)\n",
      "Evalutaion of Model:  Basic Model\n",
      "********************************************************************\n",
      "Training validations evaluations for : SVR\n",
      "[-1.82808506 -2.0903415  -1.83809987 -1.97612465 -1.78782276]\n",
      "Testing validations evaluations for : SVR\n",
      "{'r2 score': -1.9850734085895656, 'mean absolute error': 0.01681096577526437, 'mean sqaured error': 0.0003322430453001734, 'training score': -1.904094769466904, 'median absolute error': 0.01681096577526437, 'explained variance error': -4.194283299430168e-05, 'mean squared log error': 0.00023086160414568642}\n",
      "********************************************************************\n",
      "Training validations evaluations for : SGDRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28238692 0.26564975 0.27263521 0.27466754 0.26608052]\n",
      "Testing validations evaluations for : SGDRegressor\n",
      "{'r2 score': 0.16421818874099725, 'mean absolute error': 0.006636318555718803, 'mean sqaured error': 9.302374051510839e-05, 'training score': 0.27228398793869796, 'median absolute error': 0.006636318555718803, 'explained variance error': 0.16441970808967388, 'mean squared log error': 6.520521484964668e-05}\n",
      "********************************************************************\n",
      "Training validations evaluations for : BayesianRidge\n",
      "[0.47328439 0.44453382 0.44320266 0.44396148 0.43084286]\n",
      "Testing validations evaluations for : BayesianRidge\n",
      "{'r2 score': 0.40868388356358676, 'mean absolute error': 0.005363077149319752, 'mean sqaured error': 6.581435039238538e-05, 'training score': 0.44716504051875283, 'median absolute error': 0.005363077149319752, 'explained variance error': 0.4088762391773876, 'mean squared log error': 4.626754492946323e-05}\n",
      "********************************************************************\n",
      "Training validations evaluations for : LassoLars\n",
      "[-2.53478390e-04 -1.02636375e-03 -7.75761963e-05 -2.39946469e-04\n",
      " -4.39116235e-04]\n",
      "Testing validations evaluations for : LassoLars\n",
      "{'r2 score': -2.3717177887183638e-05, 'mean absolute error': 0.007618533763746668, 'mean sqaured error': 0.00011130410535684874, 'training score': -0.0004072962083531806, 'median absolute error': 0.007618533763746668, 'explained variance error': -2.3717177624282826e-05, 'mean squared log error': 7.787724876966642e-05}\n",
      "********************************************************************\n",
      "Training validations evaluations for : ARDRegression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "ModelEvaluationResults = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (m,models_) in enumerate(models):\n",
    "    df,train_X,train_Y,test_X,test_Y = models_\n",
    "    print train_X.shape\n",
    "    print train_Y.shape\n",
    "    \n",
    "    print \"Evalutaion of Model:  \"+str(model_names[m])\n",
    "    \n",
    "    clfs = [ \n",
    "        \n",
    "    SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    ,linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars(),\n",
    "    linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor()]\n",
    "    #KernelRidge(alpha=1.0, coef0=1, degree=3, gamma=None, kernel='linear',kernel_params=None)]\n",
    "\n",
    "    #clf_names = ['Logistic Regression','KNeighborsRegressor','SVR','KernelRidge']\n",
    "    clf_names = ['SVR','SGDRegressor','BayesianRidge','LassoLars','ARDRegression','PassiveAggressiveRegressor','TheilSenRegressor'\n",
    "                ]\n",
    "\n",
    "    \n",
    "    ClassifierEvaluationResults = {}\n",
    "    \n",
    "    for (i, clf_) in enumerate(clfs):\n",
    "        #clf = clf_.fit(train_X, train_Y)\n",
    "        #preds = clf_.predict(Xtest)\n",
    "        print \"********************************************************************\"\n",
    "        print \"Training validations evaluations for : \"+str(clf_names[i])\n",
    "        scores = cross_val_score(clf_, train_X, train_Y, cv=5)\n",
    "        predicted_ratings = cross_val_predict(clf_, test_X,test_Y, cv=5)\n",
    "        print scores\n",
    "        train_mean_score=scores.mean()\n",
    "        print \"Testing validations evaluations for : \"+str(clf_names[i])\n",
    "\n",
    "\n",
    "        r2 = r2_score(test_Y, predicted_ratings, multioutput='uniform_average')\n",
    "        mae = median_absolute_error(test_Y, predicted_ratings)\n",
    "        msle =mean_squared_log_error(test_Y, predicted_ratings) \n",
    "        mse = mean_squared_error(test_Y, predicted_ratings)\n",
    "        mae = mean_absolute_error(test_Y, predicted_ratings)\n",
    "        evs = explained_variance_score(test_Y, predicted_ratings)  \n",
    "        \n",
    "        data ={'training score':train_mean_score,\n",
    "            'r2 score':r2,\n",
    "            'median absolute error':mae,\n",
    "            'mean squared log error':msle,\n",
    "            'mean sqaured error':mse,\n",
    "            'mean absolute error':mae,\n",
    "            'explained variance error':evs}\n",
    "\n",
    "        #data ={'training_score':train_mean_score}        \n",
    "        \n",
    "        ClassifierEvaluationResults[clf_names[i]] = data\n",
    "        print data\n",
    "    \n",
    "    ModelEvaluationResults[model_names[m]]=ClassifierEvaluationResults\n",
    "    print ClassifierEvaluationResults\n",
    "    print \"********************************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishantrathi/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(ytest, preds, multioutput='uniform_average')\n",
    "mae = median_absolute_error(ytest, preds)\n",
    "msle =mean_squared_log_error(ytest, preds) \n",
    "mse = mean_squared_error(ytest, preds)\n",
    "mabe = mean_absolute_error(ytest, preds)\n",
    "evs = explained_variance_score(ytest, preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830426214156\n",
      "0.434626625337\n",
      "0.0355805487688\n",
      "0.544091711132\n",
      "0.55501256951\n",
      "0.832091517462\n"
     ]
    }
   ],
   "source": [
    "print r2\n",
    "print mae\n",
    "print msle\n",
    "print mse\n",
    "print mabe\n",
    "print evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Ranking\n",
    "\n",
    "clf2 = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "xtrain2 = xtrain.drop(['groupRank'], axis=1, inplace=False)\n",
    "xtest2 = xtest.drop(['groupRank'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17496, 1738)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2.fit(xtrain2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds2 = clf2.predict(xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "r2_B = r2_score(ytest, preds2, multioutput='uniform_average')\n",
    "mae_B = median_absolute_error(ytest, preds2)\n",
    "msle_B =mean_squared_log_error(ytest, preds2) \n",
    "mse_B = mean_squared_error(ytest, preds2)\n",
    "mabe_B = mean_absolute_error(ytest, preds2)\n",
    "evs_B = explained_variance_score(ytest, preds2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830426214156\n",
      "1.01368228622\n",
      "0.102643929117\n",
      "2.22747772465\n",
      "1.19279913019\n",
      "0.309231285723\n"
     ]
    }
   ],
   "source": [
    "#Output Without Group Ranking\n",
    "\n",
    "print r2_B\n",
    "print mae_B\n",
    "print msle_B\n",
    "print mse_B\n",
    "print mabe_B\n",
    "print evs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishantrathi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/nishantrathi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ytest['OP_WithRank']=preds\n",
    "ytest['OP_With_OUT_Rank']=preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>OP_WithRank</th>\n",
       "      <th>OP_With_OUT_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34344</th>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.338100</td>\n",
       "      <td>3.174727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39626</th>\n",
       "      <td>4.330733</td>\n",
       "      <td>4.833302</td>\n",
       "      <td>4.947679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19904</th>\n",
       "      <td>5.648974</td>\n",
       "      <td>5.485150</td>\n",
       "      <td>4.940090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65001</th>\n",
       "      <td>6.645091</td>\n",
       "      <td>6.954611</td>\n",
       "      <td>4.975507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16330</th>\n",
       "      <td>5.308268</td>\n",
       "      <td>5.023694</td>\n",
       "      <td>4.979165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56285</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.682361</td>\n",
       "      <td>3.521087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59334</th>\n",
       "      <td>5.513429</td>\n",
       "      <td>5.619233</td>\n",
       "      <td>5.005762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70256</th>\n",
       "      <td>5.820083</td>\n",
       "      <td>5.900209</td>\n",
       "      <td>4.926259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70451</th>\n",
       "      <td>6.248043</td>\n",
       "      <td>6.263042</td>\n",
       "      <td>3.315377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80569</th>\n",
       "      <td>5.093750</td>\n",
       "      <td>5.233761</td>\n",
       "      <td>4.940583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Facebook  OP_WithRank  OP_With_OUT_Rank\n",
       "34344  1.945910     2.338100          3.174727\n",
       "39626  4.330733     4.833302          4.947679\n",
       "19904  5.648974     5.485150          4.940090\n",
       "65001  6.645091     6.954611          4.975507\n",
       "16330  5.308268     5.023694          4.979165\n",
       "56285  1.098612     2.682361          3.521087\n",
       "59334  5.513429     5.619233          5.005762\n",
       "70256  5.820083     5.900209          4.926259\n",
       "70451  6.248043     6.263042          3.315377\n",
       "80569  5.093750     5.233761          4.940583"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytest.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
