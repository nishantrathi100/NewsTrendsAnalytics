{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = pd.read_csv('News_Final.csv')\n",
    "dfFb_Ec = pd.read_csv('Facebook_Economy.csv')\n",
    "dfFb_Ms = pd.read_csv('Facebook_Microsoft.csv')\n",
    "dfFb_Ob = pd.read_csv('Facebook_Obama.csv')\n",
    "dfFb_Pa = pd.read_csv('Facebook_Palestine.csv')\n",
    "dfGo_Pa = pd.read_csv('GooglePlus_Palestine.csv')\n",
    "dfGo_Ob = pd.read_csv('GooglePlus_Obama.csv')\n",
    "dfGo_Ms = pd.read_csv('GooglePlus_Microsoft.csv')\n",
    "dfGo_Ec = pd.read_csv('GooglePlus_Economy.csv')\n",
    "dfLd_Pa = pd.read_csv('LinkedIn_Palestine.csv')\n",
    "dfLd_Ob = pd.read_csv('LinkedIn_Obama.csv')\n",
    "dfLd_Ms = pd.read_csv('LinkedIn_Microsoft.csv')\n",
    "dfLd_Ec = pd.read_csv('LinkedIn_Economy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the items which was never shared or with share counts = 0\n",
    "df_model = dfFinal[(dfFinal.Facebook != -1) & (dfFinal.GooglePlus != -1) & (dfFinal.LinkedIn != -1) & (dfFinal.Facebook != 0) & (dfFinal.GooglePlus != 0) & (dfFinal.LinkedIn != 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edit original Data frame to assign group rank\n",
    "def assignRank(row,rankDictionary):\n",
    "    if row.IDLink in rankDictionary:\n",
    "        return rankDictionary[row.IDLink]\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rank_model(df):\n",
    "    #removing time from publish date\n",
    "    df['PublishDate'] = df['PublishDate'].astype('datetime64[ns]')\n",
    "    df['DateOnly'] = df['PublishDate'].dt.date\n",
    "\n",
    "    #count number of days since Jan 1 1970. These columns would be used to form groups of 3 days\n",
    "    df['DaysSince1'] = (pd.to_datetime(df['DateOnly']) - pd.datetime(1970,1,1)).dt.days\n",
    "    df['DaysSince1'] = df['DaysSince1'].subtract(df['DaysSince1'].min()).add(1)\n",
    "    df['DaysSince2'] = df['DaysSince1'] + 1\n",
    "    df['DaysSince3'] = df['DaysSince1'] + 2\n",
    "\n",
    "    print \"Calculating rank...\"\n",
    "    # Calculate rank of the news item within the 3 day window group\n",
    "\n",
    "    loop_start = df['DaysSince1'].min()\n",
    "    loop_end = df['DaysSince1'].max()\n",
    "    print loop_start\n",
    "    print loop_end\n",
    "    rankDictionary = {}\n",
    "    for x in range(loop_start, loop_end):\n",
    "        df_temp = df[(df.DaysSince1 == x) | (df.DaysSince2 == x) | (df.DaysSince3 == x)]\n",
    "        df_temp.sort_values(by='Facebook')# Made it ascending so that we rank them in reverse order #, ascending=False)\n",
    "        df_temp['GroupRanking'] = df_temp['Facebook'].rank(ascending=False)\n",
    "        for index, row in df_temp.iterrows():\n",
    "            if row['DaysSince1'] == x:\n",
    "                rankDictionary[row['IDLink']] = row['GroupRanking']\n",
    "    df['groupRank'] = df.apply (lambda row: assignRank (row,rankDictionary),axis=1)\n",
    "    df['Facebook'] = df['Facebook'].apply(lambda x: np.log(x + 1))\n",
    "    #Split DataFrame into X and Y\n",
    "    #df_X_Without_Rank = pd.get_dummies(df[['Source', 'Topic', 'SentimentTitle', 'SentimentHeadline']])\n",
    "    df_X = pd.get_dummies(df[['Source', 'Topic', 'SentimentTitle', 'SentimentHeadline', 'groupRank']])\n",
    "    df_Y = df[['Facebook']]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_X, df_Y, test_size=0.25)\n",
    "    return df, xtrain, ytrain,xtest, ytest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model(df):    \n",
    "    df, xtrain, ytrain,xtest, ytest = rank_model(df)\n",
    "    xtrain = xtrain.drop(['groupRank'], axis=1, inplace=False)\n",
    "    xtest = xtest.drop(['groupRank'], axis=1, inplace=False)\n",
    "    return df, xtrain, ytrain,xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rank...\n",
      "1\n",
      "243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rank...\n",
      "1\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models= [rank_model(df_model), basic_model(df_model)]\n",
    "model_names = [\"Model_With_Ranking\",\"Basic Model\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutaion of Model:  Model_With_Ranking\n",
      "********************************************************************\n",
      "Training validations evaluations for : BayesianRidge\n",
      "[0.74959283 0.75942824 0.76680772 0.75634036 0.75386762]\n",
      "Testing validations evaluations for : BayesianRidge\n",
      "********************************************************************\n",
      "{'r2 score': 0.7413247344349757, 'mean absolute error': 0.054309487111407796, 'mean sqaured error': 0.006397861517741547, 'training score': 0.7572073521050405, 'median absolute error': 0.054309487111407796, 'explained variance error': 0.7413626648592181, 'mean squared log error': 0.002090953035823874}\n",
      "********************************************************************\n",
      "********************************************************************\n",
      "Training validations evaluations for : LassoLars\n",
      "[-2.64295336e-04 -2.10724061e-04 -6.11261559e-06 -4.60948195e-05\n",
      " -1.12402161e-04]\n",
      "Testing validations evaluations for : LassoLars\n",
      "********************************************************************\n",
      "{'r2 score': -0.00017121841185185893, 'mean absolute error': 0.12490654648922847, 'mean sqaured error': 0.024737413279358668, 'training score': -0.00012792579859493002, 'median absolute error': 0.12490654648922847, 'explained variance error': -0.00017121840812772682, 'mean squared log error': 0.007293392345083203}\n",
      "********************************************************************\n",
      "*******************Evaluation Done*************************************************\n",
      "{'BayesianRidge': {'r2 score': 0.7413247344349757, 'mean absolute error': 0.054309487111407796, 'mean sqaured error': 0.006397861517741547, 'training score': 0.7572073521050405, 'median absolute error': 0.054309487111407796, 'explained variance error': 0.7413626648592181, 'mean squared log error': 0.002090953035823874}, 'LassoLars': {'r2 score': -0.00017121841185185893, 'mean absolute error': 0.12490654648922847, 'mean sqaured error': 0.024737413279358668, 'training score': -0.00012792579859493002, 'median absolute error': 0.12490654648922847, 'explained variance error': -0.00017121840812772682, 'mean squared log error': 0.007293392345083203}}\n",
      "********************************************************************\n",
      "Evalutaion of Model:  Basic Model\n",
      "********************************************************************\n",
      "Training validations evaluations for : BayesianRidge\n",
      "[0.49956414 0.48789884 0.47804624 0.47984701 0.48003677]\n",
      "Testing validations evaluations for : BayesianRidge\n",
      "********************************************************************\n",
      "{'r2 score': 0.4459665227944013, 'mean absolute error': 0.04539786235964671, 'mean sqaured error': 0.003906098749064499, 'training score': 0.48507860359210364, 'median absolute error': 0.04539786235964671, 'explained variance error': 0.4461147305806634, 'mean squared log error': 0.0015527448070584387}\n",
      "********************************************************************\n",
      "********************************************************************\n",
      "Training validations evaluations for : LassoLars\n",
      "[-2.55617136e-04 -8.21656284e-04 -9.62339563e-05 -8.53341077e-06\n",
      " -3.42361028e-09]\n",
      "Testing validations evaluations for : LassoLars\n",
      "********************************************************************\n",
      "{'r2 score': -0.0006917638321124464, 'mean absolute error': 0.06484730026039855, 'mean sqaured error': 0.007055170865520147, 'training score': -0.00023640884217619452, 'median absolute error': 0.06484730026039855, 'explained variance error': -0.0006917638300332207, 'mean squared log error': 0.002758512089529245}\n",
      "********************************************************************\n",
      "*******************Evaluation Done*************************************************\n",
      "{'BayesianRidge': {'r2 score': 0.4459665227944013, 'mean absolute error': 0.04539786235964671, 'mean sqaured error': 0.003906098749064499, 'training score': 0.48507860359210364, 'median absolute error': 0.04539786235964671, 'explained variance error': 0.4461147305806634, 'mean squared log error': 0.0015527448070584387}, 'LassoLars': {'r2 score': -0.0006917638321124464, 'mean absolute error': 0.06484730026039855, 'mean sqaured error': 0.007055170865520147, 'training score': -0.00023640884217619452, 'median absolute error': 0.06484730026039855, 'explained variance error': -0.0006917638300332207, 'mean squared log error': 0.002758512089529245}}\n",
      "********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ModelEvaluationResults = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (m,models_) in enumerate(models):\n",
    "    df,train_X,train_Y,test_X,test_Y = models_   \n",
    "    print \"Evalutaion of Model:  \"+str(model_names[m])\n",
    "    \n",
    "    clfs = [  \n",
    "    SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars()]\n",
    "    \n",
    "    #KernelRidge(alpha=1.0, coef0=1, degree=3, gamma=None, kernel='linear',kernel_params=None)]\n",
    "\n",
    "    #clf_names = ['Logistic Regression','KNeighborsRegressor','SVR','KernelRidge']\n",
    "    clf_names = ['SVR','SGDRegressor','BayesianRidge','LassoLars']\n",
    "    #clf_names = ['BayesianRidge','LassoLars']\n",
    "\n",
    "\n",
    "    \n",
    "    ClassifierEvaluationResults = {}\n",
    "    \n",
    "    for (i, clf_) in enumerate(clfs):\n",
    "        print \"********************************************************************\"\n",
    "        print \"Training validations evaluations for : \"+str(clf_names[i])\n",
    "        scores = cross_val_score(clf_, train_X, train_Y, cv=5)\n",
    "        predicted_ratings = cross_val_predict(clf_, test_X,test_Y, cv=5)\n",
    "        print scores\n",
    "        train_mean_score=scores.mean()\n",
    "        print \"Testing validations evaluations for : \"+str(clf_names[i])\n",
    "\n",
    "\n",
    "        r2 = r2_score(test_Y, predicted_ratings, multioutput='uniform_average')\n",
    "        mae = median_absolute_error(test_Y, predicted_ratings)\n",
    "        msle =mean_squared_log_error(test_Y, predicted_ratings) \n",
    "        mse = mean_squared_error(test_Y, predicted_ratings)\n",
    "        mae = mean_absolute_error(test_Y, predicted_ratings)\n",
    "        evs = explained_variance_score(test_Y, predicted_ratings)  \n",
    "        \n",
    "        data ={'training score':train_mean_score,\n",
    "            'r2 score':r2,\n",
    "            'median absolute error':mae,\n",
    "            'mean squared log error':msle,\n",
    "            'mean sqaured error':mse,\n",
    "            'mean absolute error':mae,\n",
    "            'explained variance error':evs}\n",
    "   \n",
    "        \n",
    "        ClassifierEvaluationResults[clf_names[i]] = data\n",
    "        print \"********************************************************************\"\n",
    "        print data\n",
    "        print \"********************************************************************\"\n",
    "        \n",
    "    print \"*******************Evaluation Done*************************************************\"\n",
    "    ModelEvaluationResults[model_names[m]]=ClassifierEvaluationResults\n",
    "    print ClassifierEvaluationResults\n",
    "    print \"********************************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
